import requests
from bs4 import BeautifulSoup
import os.path
import pandas as pd
from aiohttp import ClientSession
import asyncio


# Gets a movie url
# Return a html page
async def get_html(url: str, session: ClientSession, **kwargs):
    async with session.get(url, timeout=30) as response:
        assert response.status == 200
        html = await response.read()
        print("Requested")
        return html


# Gets a html code
# Returns htmls of all recommended pages
async def create_tasks(urls, session):
    print("Creating tasks...")
    reqs = []
    for url in urls:
        reqs.append(get_html(url, session))
    print(len(reqs))
    return await asyncio.gather(*reqs)


def parse_rates(html):
    soup = BeautifulSoup(html, "html.parser")
    div = soup.find("div", {"class": "lister-list"})
    for i in range(len(div)):
        try:
            comment = str(div.contents[i].contents[1].contents[1].a.text).rstrip('\n')
            rate = str(div.contents[3].contents[1].contents[1].contents[1].contents[1].contents[3])[6:-7]
            if float(rate) >= 8:
                rate = 1
            else:
                rate = 0
            df.loc[len(df)] = [comment,rate]
        except:
            continue


def write_movies(df):
    # Writing to the csv file
    path = 'D:\Machine Learning A-Z\Machine Learning Datasets'
    complete_name = os.path.join(path, 'Rating_list_2.csv')
    with open(complete_name, 'w', encoding="utf-8") as csvFile:
        try:
            csvFile.write(df.to_csv())
            print("File written")
        except Exception as e:
            print('Failed to write a file: ' + str(e))


async def main():
    async with ClientSession() as session:
        urls = []
        for id in title_ids:
            urls.append('https://www.imdb.com/title/'+ str(id)[2:-2] +'/reviews?sort=totalVotes&dir=desc&ratingFilter=0')
        for i in range(0,len(urls), 100):
            print("Requesting...")
            print("i = " + str(i))
            try:
                html_lst = await create_tasks(urls[i:i+100], session)
            except:
                print("Writing file...")
                write_movies(df)
            print(len(html_lst))
            for html in html_lst:
                parse_rates(html)
                print(len(df))
            if i % 100 == 0:
                print("Writing file...")
                write_movies(df)


if __name__ == '__main__':
    path = 'D:\Machine Learning A-Z\Machine Learning Datasets'
    complete_name = os.path.join(path, 'Movie_list.csv')
    with open(complete_name, 'r') as csvFile:
        try:
            id_dataset = pd.read_csv(csvFile)
        except:
            print("Error reading the csvFile...")
    title_ids = id_dataset.iloc[:].values
    labels = ['Comment', 'Rate']
    df = pd.DataFrame(columns=labels)
    asyncio.run(main())
